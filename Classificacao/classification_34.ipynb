{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification_34.ipynb","provenance":[{"file_id":"1Eu7Uglz1pnHgMUViNaEsdb-Ha9RlyosY","timestamp":1624885438971}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"id":"4XTyqxM7f7Ep"},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","!/opt/bin/nvidia-smi\n","!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWzoWNQef7E0"},"source":["import fastai.vision as fv\n","from fastai.callbacks.hooks import *\n","from fastai.callbacks import SaveModelCallback\n","from pathlib import Path\n","import fnmatch\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n","fv.torch.backends.cudnn.benchmark=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxpca2EnLR7Z"},"source":["!wget -O Image_Classification.zip https://arquivos.ufsc.br/f/0d2caf9d5408439ab48d/?dl=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmWfgdY4vDFW"},"source":["!unzip /content/Image_Classification.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQgjG4sCanAB"},"source":["!mkdir Output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PVKtYOAtyMA"},"source":["path = Path('/content/Output')\n","path_img = Path('/content/Image_Classification')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ieq8IBDCti-Q"},"source":["# Metrics, Initial data split and model "]},{"cell_type":"code","metadata":{"id":"eIIQL_Ggf7Fr"},"source":["src = (fv.ImageList.from_folder(path_img)\n","        .split_by_folder(valid='valid')\n","        .label_from_folder())\n","used_model = fv.models.resnet34\n","\n","metrics = [fv.accuracy]\n","\n","def plot_find_lr(getter_learner):\n","  wds_try = [1e-6, 1e-4, 1e-2]\n","  \n","  wds = []\n","  lrs = []\n","  losses = []\n","\n","  learner = getter_learner()\n","  for wd in wds_try:\n","    learner.lr_find(wd=wd)\n","    lrs.append(learner.recorder.lrs)\n","    losses.append(learner.recorder.losses)\n","    wds.append(str(wd))\n","    learner.recorder.plot()\n","\n","  _, ax = plt.subplots(1,1)\n","  min_y = 0.5\n","  max_y = 5\n","  for i in range(len(losses)):\n","    ax.plot(lrs[i], losses[i])\n","    min_y = min(np.asarray(losses[i]).min(), min_y)\n","  ax.set_ylabel(\"Loss\")\n","  ax.set_xlabel(\"Learning Rate\")\n","  ax.set_xscale('log')\n","  #ax ranges may need some tuning with different model architectures \n","  ax.set_xlim((1e-8,1e-1))\n","  ax.set_ylim((min_y - 0.02,max_y))\n","  ax.legend(wds)\n","  ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGlEhqmuf7Fx"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"RZ9KZV0Yf7F2"},"source":["bs=128\n","size=(256,256)\n","\n","data = src.transform(fv.get_transforms(flip_vert=True), size=size)\\\n","        .databunch(bs=bs)\\\n","        .normalize(fv.imagenet_stats)\n","\n","def get_learner(load_model=None, unfreeze:bool=False, path_learner:Path=None):\n","  learn = fv.cnn_learner(data, used_model, metrics=metrics).to_fp16()\n","  learn.path = path if path_learner == None else path_learner\n","  if(load_model != None):\n","    learn.load(load_model)\n","  if(unfreeze):\n","    learn.unfreeze()\n","  return learn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUrc0s3CazPo"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ic556YZD9Xa"},"source":["data.show_batch()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60W937v1f7F-"},"source":["plot_find_lr(get_learner)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bl5IDi-lti_C"},"source":["lr=slice(1e-2)\n","wd=1e-3\n","learn = get_learner()\n","callbacks = [SaveModelCallback(learn, every='improvement', monitor='accuracy', name='best_model_34_stg1')]\n","\n","fv.defaults.device = fv.torch.device('cuda')\n","learn.fit_one_cycle(15, max_lr=lr, wd=wd, callbacks=callbacks)\n","learn.save('stage1_34')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rzWGk81ti_R"},"source":["learn.show_results(rows=6, figsize=(20,30))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyktRS6_XhIB"},"source":["plot_find_lr(lambda : get_learner('best_model_34_stg1', True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ig7TE3chti_p"},"source":["# lr = slice(1e-6,1e-5)\n","lr = slice(1e-7)\n","wd=1e-2\n","learn = get_learner('best_model_34_stg1', True)\n","callbacks = [SaveModelCallback(learn, every='improvement', monitor='accuracy', name='best_model_34_stg2')]\n","\n","fv.defaults.device = fv.torch.device('cuda')\n","learn.fit_one_cycle(15, max_lr=lr, wd=wd, callbacks=callbacks)\n","learn.save('stage2_34')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bsUDGOPoKx8p"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"1r12l6w7K6Xf"},"source":["learn = get_learner('best_model_34_stg2', True, path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oK8mufvu4o-"},"source":["read_path = \"/content/Image_Classification/test\"\n","folders = os.listdir(read_path)\n","\n","preds = []\n","gt = []\n","\n","for folder in folders:\n","  images = os.listdir(os.path.join(read_path, folder))\n","\n","  for image in images:\n","    img = fv.open_image(os.path.join(read_path, folder, image))\n","    pred = learn.predict(img)\n","\n","    if str(pred[0]) == 'alterada':\n","      preds.append(0)\n","    elif str(pred[0]) == 'intermediaria':\n","      preds.append(1)\n","    elif str(pred[0]) == 'mancha':\n","      preds.append(2)\n","    elif str(pred[0]) == 'nao_identificado':\n","      preds.append(3)\n","    elif str(pred[0]) == 'neutrofilo':\n","      preds.append(4)\n","    elif str(pred[0]) == 'sobreposicao':\n","      preds.append(5)\n","    elif str(pred[0]) == 'sujeira':\n","      preds.append(6)\n","    elif str(pred[0]) == 'velhas':\n","      preds.append(7)\n","\n","    if folder == 'alterada':\n","      gt.append(0)\n","    elif folder == 'intermediaria':\n","      gt.append(1)\n","    elif folder == 'mancha':\n","      gt.append(2)\n","    elif folder == 'nao_identificado':\n","      gt.append(3)\n","    elif folder == 'neutrofilo':\n","      gt.append(4)\n","    elif folder == 'sobreposicao':\n","      gt.append(5)\n","    elif folder == 'sujeira':\n","      gt.append(6)\n","    elif folder == 'velhas':\n","      gt.append(7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5aDCvVu5P6S"},"source":["!pip install lapixdl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jM3Z6RUV3ydn"},"source":["from lapixdl.evaluation.model import Classification\n","pred_class = [Classification(x) for x in preds]\n","gt_class = [Classification(x) for x in gt]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NZEnZAT4HVP"},"source":["from lapixdl.evaluation.evaluate import evaluate_classification\n","metrics = evaluate_classification(gt_class, pred_class, ['alterada', 'intermediaria', 'mancha', 'nao_identificado', 'neutrofilo', 'sobreposicao', 'sujeira', 'velhas'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7h9vUFnXtjA2","scrolled":false},"source":["learn.show_results(rows=6, figsize=(20,30))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZH0DOQWo7d4"},"source":["interp.plot_confusion_matrix(normalize=True)"],"execution_count":null,"outputs":[]}]}